{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88535ead",
   "metadata": {},
   "source": [
    "### Gradio for NLP tasks\n",
    "\n",
    "In this notebook, we can see how to use the combination of two powerful libraries, [HuggingFace](https://huggingface.co/) and [Gradio](https://www.gradio.app/), to build Generative AI applications. Gradio allows to quickly create a simple web interface to make the access to most LLMs models more user friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2698081-4deb-436a-a821-8ea48bdd6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from transformers import pipeline       # huggingface\n",
    "import gradio as gr                     # gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a06f9",
   "metadata": {},
   "source": [
    "#### 1. Building a text summarization app\n",
    "\n",
    "With `HuggingFace` is simple to download a pretrained model for a specific task (here, summarization) and use it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31185ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pipeline\n",
    "get_completion = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(my_input):\n",
    "    my_output = get_completion(my_input)\n",
    "    return my_output[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0fc58-91d6-48f2-a014-052192586be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
    "        as an 81-storey building, and the tallest structure in Paris. \n",
    "        Its base is square, measuring 125 metres (410 ft) on each side. \n",
    "        During its construction, the Eiffel Tower surpassed the Washington \n",
    "        Monument to become the tallest man-made structure in the world,\n",
    "        a title it held for 41 years until the Chrysler Building\n",
    "        in New York City was finished in 1930. It was the first structure \n",
    "        to reach a height of 300 metres. Due to the addition of a broadcasting \n",
    "        aerial at the top of the tower in 1957, it is now taller than the \n",
    "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the \n",
    "        Eiffel Tower is the second tallest free-standing structure in France \n",
    "        after the Millau Viaduct.''')\n",
    "\n",
    "get_completion(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144593f",
   "metadata": {},
   "source": [
    "With Gradio's `gr.Interface` is possible to write a simple UI where the user can write an input and get an output, ideally without the need to see the code behind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb11460",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()                                                    # to close existing instances\n",
    "demo = gr.Interface(fn=summarize, inputs=\"text\", outputs=\"text\")  # basic interface\n",
    "demo.launch(share=False)                                          # launch locally in the notebook\n",
    "#demo.launch(share=True, server_port=int(os.environ['PORT1']))    # to launch online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66352894",
   "metadata": {},
   "source": [
    "Let's improve the interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60684b55-c7ae-4c9e-88ea-bbc2e702ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()\n",
    "demo = gr.Interface(\n",
    "    fn=summarize, \n",
    "    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n",
    "    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n",
    "    title=\"Text summarization using LLMs\",\n",
    "    description=\"Summarize any text using the `facebook/bart-large-cnn` model from `HuggingFace`.\"\n",
    ")\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b300d17",
   "metadata": {},
   "source": [
    "#### 2. Building a named entity recognition app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1043f",
   "metadata": {},
   "source": [
    "**Named-entity recognition (NER)** (also known as *(named) entity identification*, *entity chunking*, and *entity extraction*) is a task that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories (e.g., person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.).\n",
    "\n",
    "This task has become way easier since LLMs are around so, we'll show here how to use HuggingFace + Gradio to generate a handy UI for a NER app. \n",
    "\n",
    "**Note** that the final aim is have these apps running and available online. This can be achieved using the Huggingface [Inference Endpoint](https://huggingface.co/inference-endpoints), but here we'll do everything locally.\n",
    "\n",
    "The model chosen is `dslim/bert-base-NER`, a 108M parameter fine-tuned BART model on the NER task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "\n",
    "def ner(my_input):\n",
    "    my_output = get_completion(my_input)\n",
    "    return {\"text\": my_input, \"entities\": my_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c752d685",
   "metadata": {},
   "source": [
    "If we have an endpoint on HuggingFace, then:\n",
    "```py\n",
    "API_URL = os.environ['HF_API_NER_BASE'] #NER endpoint\n",
    "text = \"My name is Andrew, I'm building DeepLearningAI and I live in California\"\n",
    "get_completion(text, parameters=None, ENDPOINT_URL= API_URL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c21254-128d-446c-b6dd-e30af26d436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()\n",
    "demo = gr.Interface(\n",
    "    fn=ner,\n",
    "    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)], # ner() can take more than one inputs...\n",
    "    outputs=[gr.HighlightedText(label=\"Text with entities\")],    # ...and return more than one outputs\n",
    "    title=\"Named Entity Recognition\",\n",
    "    description=\"NER is performed using the `dslim/bert-base-NER` model from `HuggingFace`\",\n",
    "    examples=[                                                   # provide example prompts to show how the model works \n",
    "        \"Deutsche Bahn is the national railway company of Germany\", \n",
    "        \"The Sun is the closest star to Earth\"\n",
    "    ],\n",
    "    allow_flagging=\"never\",                                      # see Gradio website to understand what this does\n",
    ")\n",
    "demo.launch(share=False)#, server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f16ad4",
   "metadata": {},
   "source": [
    "`Gradio` allows for lot of flexibility when calling the `fn` function. Here we'll add a helper function that makes the output a bit more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c49e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tokens(tokens):\n",
    "    merged_tokens = []\n",
    "    for token in tokens:\n",
    "        if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n",
    "            last_token = merged_tokens[-1]         # if current token continues the entity of the last one, merge them\n",
    "            last_token['word'] += token['word'].replace('##', '')\n",
    "            last_token['end'] = token['end']\n",
    "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
    "        else:\n",
    "            merged_tokens.append(token)            # otherwise, add the token to the list\n",
    "    return merged_tokens\n",
    "\n",
    "def modified_ner(my_input):\n",
    "    my_output = get_completion(my_input)\n",
    "    merged_tokens = merge_tokens(my_output)\n",
    "    return {\"text\": my_input, \"entities\": merged_tokens}\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=modified_ner,\n",
    "    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "    title=\"Named Entity Recognition\",\n",
    "    description=\"NER is performed using the `dslim/bert-base-NER` model from `HuggingFace`\",\n",
    "    allow_flagging=\"never\",\n",
    "    examples=[                                                  \n",
    "        \"Deutsche Bahn is the national railway company of Germany, one member state of the European Union\", \n",
    "        \"The Sun is the closest star to Earth and it moves around the Galactic Center of the Milky Way\"\n",
    "    ],\n",
    ")\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81807d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to close all the ports\n",
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9774933b",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "\n",
    "Thanks to DeepLearning.AI and Gradio for the courses that inspired this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
